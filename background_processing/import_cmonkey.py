#!/usr/bin/env python
"""import_cmonkey.py
Import cmonkey-python runs to Network portal.

This script will take a result directory generated by cmonkey-python
and import the data into the Network Portal database.

It makes the following assumptions:

  - The species for the run already exists in the database
  - The gene information already exists in the database and is complete

This simplification ensures that the importer only has to be concerned with
the adding of information that was generated by cmonkey.

"""
import os
import urllib
import json
import argparse
import ConfigParser
import psycopg2
import sqlite3
from collections import defaultdict
import datetime


def cm_runinfo(conn):
    """Returns the cmonkey run information"""
    cursor = conn.cursor()
    try:
        cursor.execute('select organism,finish_time,num_rows,num_columns from run_infos')
        code, finish_time, nrows, ncols = cursor.fetchone()
        return code, finish_time, (nrows, ncols)
    finally:
        if cursor is not None:
            cursor.close()


def nwp_species_id(dstcur, orgcode):
    """check the species id"""
    dstcur.execute('select id from networks_species where short_name=%s', [orgcode])
    return dstcur.fetchone()[0]


def insert_network(dstcur, orgcode, finish_time, ratios_size, user_id=None):
    """adds a new network"""
    dstcur.execute('select id, name from networks_species where short_name=%s', [orgcode])        
    species_id, species_name = dstcur.fetchone()

    # use the version id to ensure runs do not get installed twice
    version_id = 'cmpython_2.0_%s_%d_%d_%s' % (orgcode, ratios_size[0],
                                               ratios_size[1],
                                               finish_time.replace(' ', '_'))
    dstcur.execute("select count(*) from networks_network where species_id=%s and version_id=%s",
                   [species_id, version_id])
    num_networks = dstcur.fetchone()[0]
    if num_networks > 0:
        print "WARNING: there are already networks for this species -> ignore"
        return None
    else:
        if user_id is None:
            dstcur.execute("insert into networks_network (species_id,name,data_source,description,created_at,version_id) values (%s,%s,'cmonkey-python+inferelator','',now(),%s) returning id",
                           [species_id, "%s network" % species_name, version_id])
        else:
            dstcur.execute("insert into networks_network (species_id,name,data_source,description,created_at,version_id,user_id) values (%s,%s,'cmonkey-python+inferelator','',now(),%s,%s) returning id",
                           [species_id, "%s network" % species_name, version_id, user_id])         
        return dstcur.fetchone()[0]


def insert_conditions(dstcur, nw_id, conditions):
    """copy conditions to the specified network"""
    result = {}
    for condition in conditions:
        dstcur.execute('insert into networks_condition (network_id,name) values (%s,%s) returning id',
                       [nw_id, condition])
        cond_id = dstcur.fetchone()[0]
        result[condition] = cond_id
    return result


def copy_conditions(dstcur, srcconn, nw_id):
    """copy conditions to the specified network"""
    srccur = srcconn.cursor()
    try:
        srccur.execute('select name from column_names')
        conditions = [row[0] for row in srccur.fetchall()]
        return insert_conditions(dstcur, nw_id, conditions)
    finally:
        if srccur is not None:
            srccur.close()


def copy_row_members(dstcur, srccur, maxiter, cluster, bc_id,
                     syns, gene_map, not_in_thesaurus, not_in_db_genome):
    """NOTE: gene names are quite finicky, because of inconsistent naming"""
    success_genes = 0
    srccur.execute('select distinct name from row_members rm join row_names rn on rm.order_num=rn.order_num where iteration=? and cluster=?', [maxiter, cluster])
    rowmembs = [row[0] for row in srccur.fetchall()]
    for row in rowmembs:
        # extract a set of candidate accession numbers, these can be more than one,
        # due to multiple versions etc.
        if row in syns:
            gene = syns[row]
        else:
            gene = row
            not_in_thesaurus.add(row)

        if gene in gene_map:
            dstcur.execute('insert into networks_bicluster_genes (bicluster_id, gene_id) values (%s,%s)', [bc_id, gene_map[gene]])
            success_genes += 1
        else:
            not_in_db_genome.add(gene)

    return success_genes


def copy_column_members(dstcur, srccur, maxiter, cluster, bc_id, cond_map):
    """copies the column members to the target database"""
    srccur.execute('select distinct name from column_members cm join column_names cn on cm.order_num=cn.order_num where iteration=? and cluster=?', [maxiter, cluster])
    colmembs = [cond_map[row[0]] for row in srccur.fetchall()]
    for cond_id in colmembs:
        dstcur.execute('insert into networks_bicluster_conditions (bicluster_id, condition_id) values (%s,%s)', [bc_id, cond_id])


def copy_motif_data(dstcur, srccur2, srccur3, maxiter, cluster, bc_id, gene_map,
                    not_in_db_genome):
    """copies motif related information to network portal database"""

    # select motifs for current cluster
    srccur2.execute('select mi.rowid, mi.motif_num, mi.evalue, count(ma.rowid) as num_sites from motif_infos mi join motif_annotations ma on mi.rowid=ma.motif_info_id where mi.iteration=? and mi.cluster=? group by mi.motif_num', [maxiter, cluster])
    for motif_id, motif_num, evalue, num_sites in srccur2.fetchall():
        dstcur.execute('insert into networks_motif (bicluster_id,position,sites,e_value) values (%s,%s,%s,%s) returning id', [bc_id, motif_num, num_sites, evalue])
        m_id = dstcur.fetchone()[0]

        # copy annotations
        srccur3.execute('select rn.name as gene, position, reverse, pvalue from motif_annotations ma join row_names rn on ma.gene_num=rn.order_num where motif_info_id=?', [motif_id])
        for gene, pos, reverse, pval in srccur3.fetchall():
            reverse = reverse == 1
            if gene in gene_map:
                dstcur.execute('insert into networks_motifannotation (motif_id,gene_id,position,reverse,pvalue) values (%s,%s,%s,%s,%s)', [m_id,gene_map[gene],pos,reverse,pval])
            else:
                not_in_db_genome.add(gene)

        # copy pssms
        srccur3.execute('select row,a,c,g,t from motif_pssm_rows where motif_info_id=?',
                        [motif_id])
        for row, a, c, g, t in srccur3.fetchall():
            dstcur.execute('insert into pssms (motif_id,position,a,c,g,t) values (%s,%s,%s,%s,%s,%s)', [m_id,row,a,c,g,t])


def copy_biclusters(dstcur, srcconn, nw_id, syns):
    """copy biclusters and related data (motifs)"""
    srccur = srcconn.cursor()
    srccur2 = srcconn.cursor()
    srccur3 = srcconn.cursor()

    not_in_thesaurus = set([])
    not_in_db_genome = set([])
    success_genes = 0

    try:
        srccur.execute("select max(iteration) from cluster_stats")
        maxiter = srccur.fetchone()[0]
        srccur.execute("select cluster, residual from cluster_stats where iteration=?", [maxiter])

        dstcur.execute('select species_id from networks_network where id=%s', [nw_id])
        species_id = dstcur.fetchone()[0]

        dstcur.execute('select id, name from networks_condition where network_id=%s', [nw_id])
        cond_map = {name: id for id, name in dstcur.fetchall()}

        dstcur.execute('select id, name, common_name from networks_gene where species_id=%s', [species_id])

        # map from gene to the database id, try to use the thesaurus to avoid
        # conflicts beforehand
        gene_map = {} 
        for id, name, common_name in dstcur.fetchall():
            if name in syns:
                gene_map[syns[name]] = id
            else:
                gene_map[name] = id
            if common_name in syns:
                gene_map[syns[common_name]] = id
            else:
                gene_map[common_name] = id

        for cluster, residual in srccur.fetchall():
            print "processing bicluster %d" % cluster
            dstcur.execute("insert into networks_bicluster (network_id,k,residual) values (%s,%s,%s) returning id", [nw_id, cluster, residual])
            bc_id = dstcur.fetchone()[0]

            success_genes += copy_row_members(dstcur, srccur2, maxiter, cluster, bc_id,
                                              syns, gene_map, not_in_thesaurus,
                                              not_in_db_genome)
            copy_column_members(dstcur, srccur2, maxiter, cluster, bc_id, cond_map)
            copy_motif_data(dstcur, srccur2, srccur3, maxiter, cluster, bc_id,
                            gene_map, not_in_db_genome)

        if len(not_in_thesaurus) > 0:
            print "WARNING: %d names not in thesaurus !!!" % len(not_in_thesaurus)

        if len(not_in_db_genome) > 0:
            print "WARNING: %d names not found in the NW portal genome !" % len(not_in_db_genome)

        print "# genes successfully assigned: %d" % success_genes
                
    finally:
        if srccur3 is not None:
            srccur3.close()
        if srccur2 is not None:
            srccur2.close()
        if srccur is not None:
            srccur.close()


def synonyms(config, orgcode):
    """Query the organism service to retrieve synonyms"""
    synurl = urllib.urlopen('%s/synonyms/%s' % (config.get('General', 'info.service.url'),
                                                orgcode))
    data = json.loads(synurl.read())
    result = {}
    for primary, alternatives in data.items():
        for alternative in alternatives:
            result[alternative] = primary
    return result
    

if __name__ == '__main__':
    config = ConfigParser.ConfigParser()
    config.read("default.ini")

    parser = argparse.ArgumentParser()
    parser.add_argument('--resultdir', required=True)
    args = parser.parse_args()
    print args.resultdir
    outdb = os.path.join(args.resultdir, 'cmonkey_run.db')
    srcconn = sqlite3.connect(outdb)
    orgcode, finish_time, ratios_size = cm_runinfo(srcconn)

    syns = synonyms(config, orgcode)

    dstconn = psycopg2.connect("dbname=%s user=%s password=%s" %
                               (config.get("General", "database.name"),
                                config.get("General", "database.user"),
                                config.get("General", "database.password")))
    dstcur = dstconn.cursor()
    try:
        nw_id = insert_network(dstcur, orgcode, finish_time, ratios_size)
        print "Network inserted with: ", nw_id
        if nw_id is not None:
            copy_conditions(dstcur, srcconn, nw_id)
            copy_biclusters(dstcur, srcconn, nw_id, syns)
            # TODO: import ratios
            # TODO copy motifs
            # import inferelator influences in a different module ?
        dstconn.commit()
    except:
        dstconn.rollback()
        raise
    finally:
        if dstcur is not None:
            dstcur.close()
        if dstconn is not None:
            dstconn.close()
        if srcconn is not None:
            srcconn.close()
